# -- Clickhouse cluster
cluster: clickhouse
# -- Clickhouse database
database: clickhouse
# -- Clickhouse user
user: admin
# -- Clickhouse password
password: CHAMGE_ME
# -- Clickhouse existing secret name that needs to be in the namespace where
# clickhouse is deployed into. Will not use the above password value if set
existingSecret: ""
# -- Key in the existingSecret containing the password value
existingSecretPasswordKey: ""
# -- Whether to use TLS connection connecting to ClickHouse
secure: false
# -- Whether to verify TLS certificate on connection to ClickHouse
verify: false
# -- List of external Zookeeper servers to use. Ignored if ClickhouseKeeper is enabled.
externalZookeeper:
  servers:
  - host: service-clickhouse-0-0
    port: 9181
  - host: service-clickhouse-0-1
    port: 9181
  - host: service-clickhouse-0-2
    port: 9181

# -- Enabled the built-in ClickHouse Keeper. This is an experimental feature and should be used with caution. Migrating from ClickHouseKeeper to Zookeeper is not supported.
clickhouseKeeper:
  enabled: true

image:
  # -- ClickHouse image repository.
  repository: dkr.plural.sh/clickhouse/clickhouse/clickhouse-server
  # -- ClickHouse image tag.
  tag: "22.8.11.15"
  # -- Image pull policy
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## Example:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []

# -- Toleration labels for clickhouse pod assignment
tolerations: []
# -- Affinity settings for clickhouse pod
affinity: {}
# -- Clickhouse resource requests/limits. See more at http://kubernetes.io/docs/user-guide/compute-resources/
resources:
  requests:
    cpu: 150m
    memory: 300Mi
  limits:
    cpu: 500m
    memory: 1Gi
securityContext:
  enabled: true
  runAsUser: 101
  runAsGroup: 101
  fsGroup: 101

# -- Kubernetes Service type.
serviceType: ClusterIP

# -- An allowlist of IP addresses or network masks the ClickHouse user is
# allowed to access from. By default anything within a private network will be
# allowed. This should suffice for most use case although to expose to other
# networks you will need to update this setting.
#
allowedNetworkIps:
  - "10.0.0.0/8"
  - "172.16.0.0/12"
  - "192.168.0.0/16"

persistence:
  # -- Enable data persistence using PVC.
  enabled: true

  # -- Use a manually managed Persistent Volume and Claim.
  #    If defined, PVC must be created manually before volume will be bound.
  #
  existingClaim: ""

  # -- Persistent Volume Storage Class to use.
  #    If defined, `storageClassName: <storageClass>`.
  #    If set to `storageClassName: ""`, disables dynamic provisioning.
  #    If undefined (the default) or set to `null`, no storageClassName spec is
  #    set, choosing the default provisioner.
  #
  storageClass: null

  # -- Persistent Volume size
  size: 20Gi

## -- Clickhouse user profile configuration.
## You can use this to override profile settings, for example `default/max_memory_usage: 40000000000`
## For the full list of settings, see:
## - https://clickhouse.com/docs/en/operations/settings/settings-profiles/
## - https://clickhouse.com/docs/en/operations/settings/settings/
profiles: {}

## -- Default user profile configuration for Clickhouse. !!! Please DO NOT override this !!!
defaultProfiles:
  default/allow_experimental_window_functions: "1"
  default/allow_nondeterministic_mutations: "1"

## -- Files to add to the ClickHouse config.d directory.
## See https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md#specconfigurationfiles
files:
  # TODO: check if we actually need this file by default
  # events.proto: |
  #   syntax = "proto3";
  #   message Event {
  #     string uuid = 1;
  #     string event = 2;
  #     string properties = 3;
  #     string timestamp = 4;
  #     uint64 team_id = 5;
  #     string distinct_id = 6;
  #     string created_at = 7;
  #     string elements_chain = 8;
  #   }


## -- Clickhouse cluster layout. (Experimental, use at own risk)
## For a full list of options, see https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md
## section on clusters and layouts.
layout:
  ## -- The number of shards in the cluster.
  shardsCount: 1
  ## -- The number of replicas per shard. If ClickhouseKeeper is enabled this is ignored and permanently set to 3.
  replicasCount: 3
  ## -- The custom layout for the cluster. If ClickhouseKeeper is enabled this value appended and doesn't influence the layout of the first shard with its 3 replicas.
  shards: []
    # - files:
    #     keeper_config.xml: |
    #       <clickhouse>
    #           <include_from>/tmp/clickhouse-keeper/config.d/generated-keeper-settings.xml</include_from>
    #           <keeper_server incl="keeper_server">
    #               <path>/var/lib/clickhouse-keeper</path>
    #               <tcp_port>9181</tcp_port>
    #               <four_letter_word_white_list>*</four_letter_word_white_list>
    #               <coordination_settings>
    #                   <!-- <raft_logs_level>trace</raft_logs_level> -->
    #                   <raft_logs_level>information</raft_logs_level>
    #               </coordination_settings>
    #           </keeper_server>
    #       </clickhouse>
    #   replicas:
    #     - templates:
    #         podTemplate: pod-template-clickhouse-keeper
    #         replicaServiceTemplate: replica-service-template-clickhouse-keeper
    #     - templates:
    #         podTemplate: pod-template-clickhouse-keeper
    #         replicaServiceTemplate: replica-service-template-clickhouse-keeper
    #     - templates:
    #         podTemplate: pod-template-clickhouse-keeper
    #         replicaServiceTemplate: replica-service-template-clickhouse-keeper

## -- ClickHouse settings configuration.
## You can use this to override settings, for example `prometheus/port: 9363`
## For the full list of settings, see:
## - https://clickhouse.com/docs/en/operations/settings/settings/
settings: {}
  # Uncomment those lines if you want to enable the built-in Prometheus HTTP endpoint in ClickHouse.
  # prometheus/endpoint: /metrics
  # prometheus/port: 9363
  # prometheus/metrics: true
  # prometheus/events: true
  # prometheus/asynchronous_metrics: true

## -- Default settings configuration for ClickHouse. !!! Please DO NOT override this !!!
## default_database is set automatically by the chart using the database value and cannot be overridden.
defaultSettings:
  format_schema_path: /etc/clickhouse-server/config.d/

## -- specify additional user configs for ClickHouse. This will be added to
## the users.xml configuration. See
## https://github.com/Altinity/clickhouse-operator for details.
additionalUsersConfig:

## -- ClickHouse pod(s) annotation.
podAnnotations:
  # Uncomment those lines if you want Prometheus server to scrape ClickHouse pods metrics.
  # prometheus.io/scrape: "true"
  # prometheus.io/path: /metrics
  # prometheus.io/port: "9363"

## -- Clickhouse pod distribution.
podDistribution:
  # Uncomment to have replicas of each shard reside on different hosts.
- scope: Shard
  type: ShardAntiAffinity
  topologyKey: kubernetes.io/hostname

## -- Enable default Clickhouse pod topology spread constraint that spread the pods of this clickhouse installation across availability zones
defaultTopologySpreadConstraints:
  enabled: true
# Enabled the following
# - maxSkew: 1
#   topologyKey: topology.kubernetes.io/zone
#   whenUnsatisfiable: DoNotSchedule
#   labelSelector:
#     matchExpressions:
#     - key: clickhouse.altinity.com/chi
#       operator: In
#       values:
#       - {{ template "clickhouse.fullname" . }}

## -- Clickhouse pod topology spread constraint. If defaultTopologySpreadConstraints is enabled this will be appended to the default constraints.
topologySpreadConstraints: []

client:
  image:
    # -- ClickHouse image repository.
    repository: dkr.plural.sh/clickhouse/clickhouse/clickhouse-server
    # -- ClickHouse image tag.
    tag: "22.8.11.15"
    # -- Image pull policy
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []

backup:
  # https://github.com/AlexAkulov/clickhouse-backup
  enabled: false
  image:
    # -- Clickhouse backup image repository.
    repository: dkr.plural.sh/clickhouse/altinity/clickhouse-backup
    # -- ClickHouse backup image tag.
    tag: "2.3.0"
    # -- Image pull policy
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []

  backup_user: backup
  # password in plain text because it's using in cronjob
  backup_password: backup_password
  # -- Use an existing secret name in the deployed namespace for the backup
  # password
  existingSecret: ""
  # -- Key in the existingSecret containing the password value
  existingSecretPasswordKey: ""
  backup_schedule: "0 0 * * *" # backup every day at 0:00

  # All options: https://github.com/AlexAkulov/clickhouse-backup#default-config
  env:
    - name: LOG_LEVEL
      value: "debug"
    - name: ALLOW_EMPTY_BACKUPS
      value: "true"
    - name: API_LISTEN
      value: "0.0.0.0:7171"
    # INSERT INTO system.backup_actions to execute backup
    - name: API_CREATE_INTEGRATION_TABLES
      value: "true"
    - name: BACKUPS_TO_KEEP_REMOTE
      value: "0"
    # Add settings for remote backup storage.

busybox:
  image:
    # -- Busybox image repository.
    repository: busybox
    # -- Busybox image tag.
    tag: 1.34.0
    # -- Image pull policy
    pullPolicy: IfNotPresent
  pullSecrets: []

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

pluralRunbook:
  enabled: true

preDeleteInstallationHook:
  image:
    repository: bitnami/kubectl
    tag: 1.27.3
  enabled: true

postInstallationHook:
  name: ch-cluster-ready
  enabled: true
  annotations:
    helm.sh/hook: post-install
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
    helm.sh/hook-weight: "0"
  initContainer:
    timeout: "180s"
    image:
      repository: bitnami/kubectl
      tag: 1.27.3
  image:
    repository: curlimages/curl
    tag: 7.79.1
  command: ["sh", "-c"]
  args:
    - curl -Sv "${CLICKHOUSE_HOST}/?user=${CLICKHOUSE_USER}&password=${CLICKHOUSE_PASSWORD}" -d "SELECT 1" && sleep 10
  envFrom: []
  env:
    - name: CLICKHOUSE_HOST
      value: service-{{ include "clickhouse.fullname" . }}-{{ .Values.cluster }}.{{ .Release.Namespace }}.svc.cluster.local:8123
    - name: CLICKHOUSE_PASSWORD
      value: "{{ .Values.password }}"
    - name: CLICKHOUSE_USER
      value: "{{ .Values.user }}"
  backoffLimit: 6
  role:
    rules:
      - apiGroups: ["clickhouse.altinity.com"]
        resources: ["clickhouseinstallations"]
        verbs: ["delete", "deletecollection", "get", "list", "patch", "create", "update", "watch"]
